# -*- coding: utf-8 -*-
"""pca_from_scratch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/888Sima/10506120a42238d15bd74be0abb1f7c0/another-copy-of-pca-example.ipynb
"""

import numpy as np

def standardize_data(X):
    """
    Standardize features by removing the mean and scaling to unit variance.
    """
    mean = np.mean(X, axis=0)
    std_dev = np.std(X, axis=0)
    X_standardized = (X - mean) / std_dev
    return X_standardized

def compute_covariance_matrix(X):
    """
    Compute the covariance matrix of the standardized data.
    """
    n_samples = X.shape[0]
    covariance_matrix = np.dot(X.T, X) / (n_samples - 1)
    return covariance_matrix

def compute_eigenvalues_and_eigenvectors(cov_matrix):
    """
    Calculate eigenvalues and eigenvectors from the covariance matrix.
    """
    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)
    return eigenvalues, eigenvectors

def sort_eigenvalues_and_eigenvectors(eigenvalues, eigenvectors):
    """
    Sort eigenvalues and corresponding eigenvectors in descending order.
    """
    sorted_indices = np.argsort(eigenvalues)[::-1]
    sorted_eigenvalues = eigenvalues[sorted_indices]
    sorted_eigenvectors = eigenvectors[:, sorted_indices]
    return sorted_eigenvalues, sorted_eigenvectors

def project_onto_principal_components(X, eigenvectors, n_components):
    """
    Project the data onto the top 'n' principal components.
    """
    top_eigenvectors = eigenvectors[:, :n_components]
    X_pca = np.dot(X, top_eigenvectors)
    return X_pca

# Example Usage

# Load the Iris dataset
from sklearn.datasets import load_iris
data = load_iris()
X = data.data
y = data.target

# Step 1: Standardize the data
X_standardized = standardize_data(X)

# Step 2: Compute the covariance matrix
cov_matrix = compute_covariance_matrix(X_standardized)

# Step 3: Calculate eigenvalues and eigenvectors
eigenvalues, eigenvectors = compute_eigenvalues_and_eigenvectors(cov_matrix)

# Step 4: Sort eigenvalues and eigenvectors
sorted_eigenvalues, sorted_eigenvectors = sort_eigenvalues_and_eigenvectors(eigenvalues, eigenvectors)

# Step 5: Project the data onto the top 2 principal components
X_pca = project_onto_principal_components(X_standardized, sorted_eigenvectors, n_components=2)

# Print results
print("Original data shape:", X.shape)
print("PCA data shape:", X_pca.shape)
print("\nExplained variance ratio of the top components:")
explained_variance_ratio = sorted_eigenvalues / np.sum(sorted_eigenvalues)
print(explained_variance_ratio[:2])  # Display the ratio for the top 2 components

# Optional: Visualization
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolor='k')
plt.colorbar(scatter, label='Target')
plt.title('PCA Visualization of the Iris Dataset')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.grid(True)
plt.show()